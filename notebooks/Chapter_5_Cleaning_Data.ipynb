{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='menu'></a>\n",
    " <hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> \n",
    "\n",
    " ![learning academy and data science campus logos](../images/la_dsc_logo.jpg)\n",
    "  <hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.25\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python\n",
    "## Chapter 5 – Cleaning Data\n",
    "***\n",
    "Follow along with the code by running cells as you encounter them\n",
    "***\n",
    "*Chapter Overview/ Learning Objectives*\n",
    "\n",
    "* [Packages and Datasets](#packages)\n",
    " * Packages\n",
    " * Data\n",
    " \n",
    " \n",
    "* [Copies and Views](#copies)\n",
    "\n",
    "\n",
    "* [Updating Values](#updating_values)\n",
    " * Using `.loc[]`\n",
    " * Using `.str` methods\n",
    " * Changing column types\n",
    " \n",
    "\n",
    "* [Changing Column Names](#column_names)\n",
    " * Changing column name values\n",
    " * Removing spaces\n",
    " * Lower Case\n",
    "\n",
    "\n",
    "* [Missing Values](#missing)\n",
    " * What are mising values?\n",
    " * Null values when reading in data\n",
    " * Filling null values\n",
    " * Dropping null values\n",
    "\n",
    "\n",
    "* [Tidy Data](#tidy)\n",
    "\n",
    "This chapter covers the cleaning of our data; and this is important to do at a very early step after you read in your data.\n",
    "\n",
    "We show this chapter after chapter 4, as some of the concepts are slightly trickier and we want you to have more experience of working with Python and Pandas before we introduce it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='packages'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "As a reminder – we should always import our packages at the top of our script.\n",
    "\n",
    "\n",
    "In this session we will use `pandas`, and give it the nickname `pd`.\n",
    "\n",
    "Complete this action in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Pandas into this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the \"solution\" cell if you need help - or revisit chapter 2.\n",
    "\n",
    "Practicing these basic commands helps your retention of the skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution - These cells contain answers for the exercises.\n",
    "#Run once to reveal the code.\n",
    "#Run again to reveal the output. \n",
    "\n",
    "%load ../solutions/chapter_5/importpandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Good practice should also be to import our datasets at the top of our script too.\n",
    "\n",
    "In this session we’ll be using:\n",
    "\n",
    "\n",
    "|variable name |file name      |\n",
    "|:--| :------|\n",
    "|animals       |animals.csv    |\n",
    "|titanic       |titanic.xlsx   |\n",
    "|pun_animals   |pun_animals.csv|\n",
    "\n",
    "\n",
    "These are all straight forward data imports with no additional parameters.\n",
    "\n",
    "Use the cell below to load in these datasets.\n",
    "\n",
    "If you are stuck use the solution cell; remember practicing simple commands is important for retaining the skills you’re learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import your datasets here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution - These cells contain answers for the exercises.\n",
    "#Run once to reveal the code.\n",
    "#Run again to reveal the output. \n",
    "\n",
    "%load ../solutions/chapter_5/module_five_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your variables are loaded by using `%whos` in Jupyter. In Spyder or other IDE's they should appear in your variable explorer. \n",
    "\n",
    "If you struggle with this section – review Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='copies'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copies and Views\n",
    "\n",
    "It’s easy to think that the actions we’ve done so far, like filtering and copying create a brand new version of a DataFrame.\n",
    "\n",
    "This isn’t always the case. Sometimes we create what’s known as a view.\n",
    "\n",
    "On the top `cats` - highlighted in red is a subset or \"view\" of the original `cat_dog` DataFrame, where as on the bottom it’s a new unique object called `cats`.\n",
    "\n",
    "![a](../images/view_copy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes when experimenting with code it’s desirable to create another version of our DataFrame to experiment around on.\n",
    "You may think this done as following:\n",
    "\n",
    "`animals_new = animals`\n",
    "\n",
    "However this creates a view of our DataFrame, and as we’re experimenting we may not want to have our effects filter though.\n",
    "We can ensure we’re working on a fresh copy of a DataFrame by using `.copy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animals2 = animals.copy() # The correct way to create a copy of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Views and copies can potentially create issues when we try and make changes to DataFrames.\n",
    "\n",
    "Here I’m changing the name of `Pico de Gato` to Salsa. Pico de gallo is a kind of salsa, “gato” is Spanish for cat. The best jokes are always the ones you have to explain.\n",
    "\n",
    "Depending on my desired outcome I may want my changes to apply to **both** `cat_dog` and `cats`, like on the top by modifying a view, or I may just want them to apply to `cats` by modifying a copy like on the bottom.\n",
    "\n",
    "![an image showing modifications to a copy and a view](../images/modify_view_copy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see a ` SettingWithCopyWarning` warning. This is a warning, not an error so your code will still work; but if you see this you should think about what you want the outcome to be.\n",
    "\n",
    "Common reasons for this include what’s known as chained assignment.\n",
    "\n",
    "The cell below uses chained assignment to update the words `Bull` in the `animals2`  DataFrame to `Cow`.\n",
    "\n",
    "Because this is happening in a slice - ` animals2[animals2[\"AnimalGroupParent\"] == \"Bull\"]` we get this error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animals2[animals2[\"AnimalGroupParent\"] == \"Bull\"][\"AnimalGroupParent\"] = \"cow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests using `.loc[]` instead - we will use this method in the next section.\n",
    "\n",
    "When the filter is applied to `animals2` it appears as if the action has not happened.\n",
    "\n",
    "It has, but has not been applied to `animals2` , just the slice in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "animals2[animals2[\"AnimalGroupParent\"]== \"Bull\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain methods update the original DataFrame and not a copy of it, for example `.loc[]`, `.fillna()` and `dropna()`\n",
    "\n",
    "This is quite a technical element for an introduction course; don't worry if you don't understand it at the moment. The following approaches in this course are considered best practice.\n",
    "\n",
    "Generally speaking\n",
    "\n",
    "* All operations generate a copy\n",
    "* If `inplace=True` is provided, it will modify in-place; only some operations support this\n",
    "* An indexer that sets, e.g. .loc/.iloc/.iat/.at will set inplace.\n",
    "* An indexer that gets on a single-dtyped object is almost always a view (depending on the memory layout it may not be that's why this is not reliable). This is mainly for efficiency. (the example from above is for .query; this will always return a copy as its evaluated by numexpr)\n",
    "* An indexer that gets on a multiple-dtyped object is always a copy.\n",
    "[Stack Overflow Source](https://stackoverflow.com/questions/23296282/what-rules-does-pandas-use-to-generate-a-view-vs-a-copy)\n",
    "\n",
    "This [numpy tutorial](https://www.jessicayung.com/numpy-views-vs-copies-avoiding-costly-mistakes/) discusses copies and views in more detail. The rules for DataFrames are less explicit, but more information can be found [with this Dataquest tutorial]( https://www.dataquest.io/blog/settingwithcopywarning/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='updating_values'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .loc[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve already seen one action of `.loc[]` when we created our new Boolean column with the missing values.\n",
    "\n",
    "`.loc[]` can be used to access groups of rows and columns by either using labels or a Boolean array. In fact you could do any of the selection we did in Chapter 4 this way. \n",
    "\n",
    "However here we’re going to use `.loc[]` to update some values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we’re looking at the unique values of the `AnimalGroupParent` column.\n",
    "\n",
    "Here we can see two values `Cow` and `Bull` that relate to the same kind of animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animals[\"AnimalGroupParent\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analysis purposes I want to change `Bull` to `Cow` so I can look at all of my bovine related incidents together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the values using .loc[]\n",
    "animals.loc[animals[\"AnimalGroupParent\"] == \"Bull\", \"AnimalGroupParent\"]  = \"Cow\"\n",
    "\n",
    "# Filter to show my new DataFrame (notice the top row was Bull and is now Cow)\n",
    "animals[animals[\"AnimalGroupParent\"] == \"Cow\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.loc[]` takes two arguments.\n",
    "\n",
    "The first is my conditional look up. In the `AnimalGroupParent` column of the `animals` DataFrame, look for the value that is “Bull”.\n",
    "\n",
    "The second is the column I wish to update, here I wish to update/overwrite the column `AnimalGroupParent`.\n",
    "\n",
    "After closing the `.loc[]` statement I use an `= ` and give my new value; here `Cow`.\n",
    "\n",
    "When looking at the DataFrame our first row returned has the description “Bull in distress” – this was previously `Bull` in `AnimalGroupParent`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:50%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.5\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use `.loc[]` to change the value `Lamb` to `Sheep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution - These cells contain answers for the exercises.\n",
    "# Run once to reveal the code\n",
    "# Run again to reveal the output\n",
    "\n",
    "%load ../solutions/chapter_5/loc_exercise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:50%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.5\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .str methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your columns are of the `object` type (a.k.a strings or text values) we can manipulate these using `.str` methods.\n",
    "\n",
    "This is really important where our data contains the same values but different capitalisation; remember that Python would treat “Cat” and “cat” as two different values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note the values \"cat\" and \"Cat\" both exist.\n",
    "\n",
    "pun_animals[\"animal_type\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may for example want to make all of our data in `pun_animals` DataFrame `animal_type` column lowercase so that Python treats them as one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change Animal Group Parent to lower\n",
    "\n",
    "pun_animals[\"animal_type\"] = pun_animals[\"animal_type\"].str.lower()\n",
    "\n",
    "# View the change by looking at the unique values\n",
    "\n",
    "pun_animals[\"animal_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There’s a lot of other Python String methods for you to explore [within the python documentation]( https://docs.python.org/2.4/lib/string-methods.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing column types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the common frustrations in any programming language can be columns not being interpreted as we think they should. This was mentioned in Chapter 4 when we looked at `.dtypes`.\n",
    "\n",
    "When we look at the `.dtypes` for `pun_animals` we can notice that all of our columns have read in as `object` or text values.\n",
    "\n",
    "We would expect `age`, `weight` and `steps_per_day` to read in as numerical.\n",
    "\n",
    "Python interprets these as `objects` because this preserves the original features of the column. This leaves how, and when, to update the column up to us.\n",
    "\n",
    "In this section we’ll fix `age` and `weight`. \n",
    "\n",
    "`steps_per_day` will be fixed in the section on missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s fix the `age` column together.\n",
    "\n",
    "The process of changing the data type of a column should be thought of as a 3-step process:\n",
    "\n",
    "1.\tIdentify – What’s the problem\n",
    "2.\tFix – Update or change the values to amend the issue\n",
    "3.\tConvert – Change the Data Type of the column.\n",
    "\n",
    "The examples we’re fixing here are obviously simplified examples using simple data. \n",
    "\n",
    "These should hopefully give you the tools to work with your own, rather more complicated data later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `pun_animals` is such a small DataFrame we could just print out the whole DataFrame or our affected Series to find the error.\n",
    "This works when we only have 10 rows of data, but would be much harder to see with 10,000!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes for \"global\" issues, like commas in numerics (100,000) we can use methods like `.head()` and `.tail()` - but there are other useful methods too:\n",
    "\n",
    "A useful python string method is `.str.isalpha()` . This returns us a Boolean series - `True` if the string contains alphabet values (e.g a combination of A-Z) and `False` if it contains something else – like numeric values (e.g only the values 0-9).\n",
    "\n",
    "Likewise `.str.isalnum()` will return `True` if the string contains alphabetic or numeric values, but `False` if there are symbols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals[\"age\"].str.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put this in a filter to just return the row that’s `alpha` and therefore “wrong”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals[pun_animals[\"age\"].str.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the input was `One` as a word – not a numeric.\n",
    "\n",
    "We’ve now completed step 1 – Identify the issue.\n",
    "\n",
    "Step 2 – Fix the issue can be done in a variety of different ways.\n",
    "\n",
    "Here I’m going to use `.loc[]` but you can use `.str` methods too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.loc[pun_animals[\"age\"] == \"One\", \"age\"] = 1\n",
    "\n",
    "# Print the Series to see the change\n",
    "pun_animals[\"age\"]\n",
    "\n",
    "# This will also work\n",
    "# pun_animals = pun_animals[\"age\"].str.replace( patt = \"One\", repl = \"1\") # Note here the \"1\" must be a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that even though we have now “fixed” the problem – the “One” is now 1 – the dtype of the column is still `object`.\n",
    "\n",
    "There are a few ways of converting the type. Here we’ll use `pd.to_numeric()` - but we can also use `.astype(\"int64\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals[\"age\"] = pd.to_numeric(pun_animals[\"age\"])\n",
    "\n",
    "# Check out the dtypes change\n",
    "pun_animals[\"age\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that’s important to note here is that this conversion using `pd.to_numeric()` **only** works because we’ve already dealt with the issue in the column that was causing it to be read as an object.\n",
    "\n",
    "If we try running this on the `weight_kg` column; we’ll get an error. This is because we’ve not fixed the problem yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Cell will cause an error!\n",
    "\n",
    "pun_animals[\"weight_kg\"] = pd.to_numeric(pun_animals[\"weight_kg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:50%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.5\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Change the `weight_kg` column to a `float` datatype.\n",
    "\n",
    "Remember the 3 step process:\n",
    "\n",
    "1. Identify the problem\n",
    "2. Fix the problem\n",
    "3. Convert the Datatype\n",
    "\n",
    "Try inverting (with a ~) the filter statement using `.str.isdigit()` may help you find the errant value!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution - These cells contain answers for the exercises.\n",
    "#Run once to reveal the code.\n",
    "#Run again to reveal the output. \n",
    "\n",
    "%load ../solutions/chapter_5/changing_col_types_exercise.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get two different errors here\n",
    "\n",
    "``` python\n",
    "Can only use .str accessor with string values, which use np.object_ dtype in pandas\n",
    "```\n",
    "or\n",
    "\n",
    "``` python\n",
    "C:\\Python36\\lib\\site-packages\\pandas\\core\\ops.py:798: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
    "  result = getattr(x, name)(y)```\n",
    "\n",
    "You’ve already changed the column to the numeric data type and you’re trying to run the replace values part of your code again – therefore this is failing. Try checking the datatype of your column, or searching for the error again to see if you need to do anything else.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='column_names'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll often want to change column names.\n",
    "As we’ve seen so far Python is not particularly fussy about what our column names are; for good practice column names should:\n",
    "\n",
    "* Avoid spaces (use underscores),\n",
    "* Not start with a number,\n",
    "* Remove symbols where possible,\n",
    "* Use lower case letters.\n",
    "\n",
    "Keeping a standard convention on our column names helps us as coders to remember what they are, as well as making cross compatibility with other languages easier. Some languages can be very particular about column names.\n",
    "\n",
    "As we’ve seen earlier we access the columns using the `.columns` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "\n",
    "We can rename columns in a variety of ways.\n",
    "\n",
    "Here we'll look at the `.rename()` method.\n",
    "\n",
    "The parameter `columns = ` takes a dictionary with the old name as the key and the new name as the value.\n",
    "\n",
    "The parameter and argument `inplace=True` means that this will update the DataFrame in situ; we don’t have to worry about putting `pun_animals= ` at the start.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.rename(columns={\"name\": \"pet_name\"}, inplace=True)\n",
    "\n",
    "pun_animals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now if you re-run any earlier code that uses the column \"`name`\" it will bring you up a `key_error` warning as this name no longer exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Spaces\n",
    "\n",
    "To remove spaces we can use the `columns.str.replace()` method.\n",
    "\n",
    " `.str.replace()` takes two arguments:\n",
    " \n",
    "**`pat` = The pattern, or thing we want to change. **\n",
    "\n",
    "A space is denoted by a string with a space in it - `” “`. \n",
    "\n",
    "\n",
    "**`repl` = Replace, or the new value we want to use. **\n",
    "\n",
    "Here an underscore; again given as a string `”_”`.\n",
    "\n",
    "\n",
    "We’re performing the `.str.replace()` method on the `.columns` attribute of our DataFrame – `pun_animals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.columns = pun_animals.columns.str.replace(pat=\" \", repl=\"_\")\n",
    "\n",
    "pun_animals.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be extended by using regular expressions, if you have more complicated replaces to run. Chapter 4 contains some links to regular expression guides in the filter section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to lower case\n",
    "\n",
    "We can use other `.str.` methods on our columns attribute too if needed – things like `.columns.str.lower()` will make our column headers lower case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals.columns = pun_animals.columns.str.lower()\n",
    "\n",
    "pun_animals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are packages available that will allow you to clean your column names using a single function.\n",
    "\n",
    "\n",
    "For those of you familiar with the `R` statistical software package `Janitor` there is a Python version – [pyjanitor]( https://pyjanitor.readthedocs.io/) which has a method [ .clean_names() ](https://pyjanitor.readthedocs.io/reference/janitor.functions/janitor.clean_names.html#janitor.clean_names). \n",
    "\n",
    "These packages are not included in Anaconda, so require installation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='missing'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are mising values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing (or null) values in Pandas are represented by `NaN`.\n",
    "\n",
    "`NaN` is an acronym for Not a Number; but `pandas` uses this value to represent missing values in both numeric (`float`) and text (`object`) based columns.\n",
    "\n",
    "When writing code we can use the value `None` to represent missing values.\n",
    "\n",
    "If you have the `Numpy` package installed using `import numpy as np` you can use `np.nan` to represent missing values too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First import numpy as np\n",
    "# Again \"proper\" convention says we should do this at the top of our code\n",
    "# But as we're only using it for this cell, and this is a training notebook - we'll import it here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series with some missing values\n",
    "# Again - we usually don't create our own Series, but just for a demonstration here\n",
    "\n",
    "missing_series = pd.Series([np.nan, 4, 5, 5, None, 12, 18, 17] )\n",
    "\n",
    "# Print out the missing Series\n",
    "\n",
    "missing_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values when reading in data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we read in Data using the various `pd.read_` methods `pandas` will handle some of our missing data values for us.\n",
    "If we look in the doc string from `pd.read_csv()` we can see under the `na_values` parameter that there are some default values that are interpreted as missing.\n",
    "\n",
    "```{python}\n",
    "\n",
    "By default the following values are interpreted as\n",
    "    `NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', `\n",
    "    '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'nan'`.  \n",
    "```\n",
    "\n",
    "If you look at the `pun_animals` DataFrame in Excel, you’ll see that within the column `steps_per_day`:\n",
    "\n",
    " ![missing values from excel](../images/missing_value.jpg)\n",
    " \n",
    "`Pico de Gato`’s value was N/A\n",
    " \n",
    "`Arf Vader`’s was NaN. \n",
    "\n",
    "You’ll notice that I’ve also used a `.` to represent missing data for `Voldetort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pico de Gato` and `Arf Vader` have been interpreted as the missing data type “NaN”.\n",
    "\n",
    "`Voldetort` has not - pandas does not interpret the `.` automatically as a missing data type.\n",
    "\n",
    "If we check the `dtypes` the column has been interpreted an object (text); because of the full stop `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals[\"steps_per_day\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two options:\n",
    "\n",
    "The first is telling `pandas` to recognise the \".\" character as a null value. If we look back in the doc string at the `na_values= ` parameter we can see that we can pass `Additional strings to recognize as NA/NaN’.`\n",
    "\n",
    "We could reimport our data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/pun_animals.csv\", na_values =\".\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here I’m **NOT** assigning the output of the `pd.read_csv()` function to a variable. \n",
    "\n",
    "This is on purpose, so as not to overwrite the earlier cleaning we did!\n",
    "\n",
    "If you want to suppress the default missing values for whatever reason the parameter\n",
    "\n",
    "`keep_default_na = False`\n",
    "\n",
    "Also exists. If I set this as `False` the only things Pandas will treat as missing values are the ones we specify in `na_values = `.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the missing value in place.\n",
    "\n",
    "The second method to correct the column is to fill and replace the value. As i've already done some cleaning and processing to this data, if we read the data back in, we’d have to perform this cleaning again.\n",
    "\n",
    "If you know that there’s non standard missing values, it’s best to sort them out when you load in your data; but they can be handled later – using methods like `.loc[]` and then converting to a numerics with `pd.to_numeric()` like we’ve seen before.\n",
    "\n",
    "You may notice that the columns `.dtype` is now `float64` - Older versions of Pandas do not have a missing data type for integers.\n",
    "\n",
    "Panda’s has introduced a nullable integer data type from version 1.0.0. You can find more information about that version [in this link]( https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html) as the majority of our learners use an older versions of Pandas we don’t cover it in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct the issue - and set \".\" to None\n",
    "\n",
    "pun_animals.loc[pun_animals[\"steps_per_day\"] == \".\", \"steps_per_day\"] = None\n",
    "\n",
    "# Convert column into numbers\n",
    "\n",
    "pun_animals[\"steps_per_day\"] = pd.to_numeric(pun_animals[\"steps_per_day\"])\n",
    "\n",
    "# Check dytpes to see if it's worked\n",
    "\n",
    "pun_animals[\"steps_per_day\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before – if you run this cell twice you’ll get an error message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling with a value.\n",
    "\n",
    "We can now handle our missing values. \n",
    "\n",
    "There’s a wide variety of approaches you may wish to take here, you can:\n",
    "* Fill your missing values with a static number\n",
    "* Fill with a summary statistic (see Chapter 6)\n",
    "* Drop those rows from your dataframe.\n",
    "* Use more advanced packages like SciPy which give functions like [`.interpolate()` ]( https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html) \n",
    "\n",
    "\n",
    "What you do; and how you do it should always be led by the data you have and what the best, most appropriate decision for the analysis of the data is. \n",
    "\n",
    "There are also editing and imputation course on the learning hub that may help your decisions. These are theory based; but can give you starting points to find python methods.\n",
    "\n",
    "Below we're going to fill with a value -  there are multiple ways to do this within Python.\n",
    "\n",
    "We’re going to use the `.fillna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a copy so we're not doing this on our original data\n",
    "\n",
    "pun_animals_fill = pun_animals.copy()\n",
    "\n",
    "\n",
    "# Create a value to fill my missing values with by rounding the mean of the steps per day column to the nearest whole number\n",
    "\n",
    "missing_puns = round(number=pun_animals_fill[\"steps_per_day\"].mean(), ndigits=0 ) # in later Python versions this may be digits = \n",
    "\n",
    "# Fill missing values\n",
    "pun_animals_fill[\"steps_per_day\"].fillna(value = missing_puns,\n",
    "                                         inplace=True) \n",
    "\n",
    "# View the DataFrame\n",
    "\n",
    "pun_animals_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I’m passing two arguments to `fillna()`.\n",
    "\n",
    "`value= ` is the value I wish to fill with. This can be a static value, or in this case I’m filling with the mean of the column, rounded to the nearest whole number using `round()`\n",
    "\n",
    "We’ll look at summary statistics in the next session. \n",
    "\n",
    "Note the column type is still a float; but I could convert it to an int if I wished – now I have no missing values.\n",
    "\n",
    "`inplace=True` fills the data frame in place rather than returning a new value. \n",
    "\n",
    "Note that this has given the tortoise 5384 steps and although we’re not discussing the statistical implications here it’s good to highlight that this can skew your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:75%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:0.75\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping null values\n",
    "\n",
    "Sometimes we’ll want to drop missing values.\n",
    "\n",
    "Again as with all of the other examples, how you handle missing values should be first thought of in an analytical fashion, then enacted in python. Appropriate methods will vary depending on your data.\n",
    "\n",
    "We can drop missing values easily with `dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make another copy of our pun_animals DataFrame\n",
    "\n",
    "pun_animals_drop = pun_animals.copy()\n",
    "\n",
    "# Drop missing rows\n",
    "\n",
    "pun_animals_drop.dropna(axis=0, how=\"any\", inplace= True)\n",
    "\n",
    "# Show DataFrame\n",
    "pun_animals_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`axis=0 ` will drop rows with null values.\n",
    "\n",
    "`how=“any” ` will drop a row if any value is null. We could use “all” to drop the row if all values are missing.\n",
    "\n",
    "Note we’ve lost `Pico De Gato`, `Voldetort` and `Arf Vader`\n",
    "\n",
    "Notice again here that the index has not been reset. We can do this with the `.reset_index()` method we’ve used earlier in the course.\n",
    "\n",
    "``` python\n",
    "\n",
    "pun_animals_drop.reset_index(drop=True, inplace=True)\n",
    "\n",
    "```\n",
    "\n",
    "Another commonly used parameter is `subset=[column_names]`, often we dont need to remove all of a row because one column has missing data and we can use this to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pun_animals_drop.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tidy'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Data\n",
    "\n",
    "It’s estimated that Data Scientists spend 60% to 80% of their time on cleaning and preparing data. We’ve just scraped the surface of what you can do to clean your data, and we’ve used relatively simple data for these examples.\n",
    "\n",
    "As you work with Python you will find new scenarios and will be able to use the tools you’ve gained in these chapters to find solutions to your problems.\n",
    "\n",
    "It’s impossible to have a section of the course about tidying data without talking about tidy data.\n",
    "[The tidy data paper]( http://vita.had.co.nz/papers/tidy-data.pdf) by Hadley Wickham; written for the R programming language tries to provide a standard-ish way of organising data within a dataset.\n",
    "\n",
    "We recommend reading the paper; as the concepts explained within are applicable across languages.\n",
    "\n",
    "An explanation of applying the practices of tidy data in Python can be found in this tutorial by [Jean-Nicholas Hould]( https://www.jeannicholashould.com/tidy-data-in-python.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='END'></a>\n",
    "<hr style=\"width:100%;height:4px;border-width:0;color:gray;background-color:#003d59; opacity:1\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we’ve explored:\n",
    "* The differences between a new DataFrame and a copy of a DataFrame\n",
    "* Updating Values in our DataFrame using `.loc[]`, string methods\n",
    "* Changing column data types\n",
    "* Changing column names\n",
    "* Cleaning column names\n",
    "* A basic introduction to missing values\n",
    "* An exploration of the concepts of Tidy Data.\n",
    "\n",
    "\n",
    "You have completed chapter 5 of the Introduction to Python course. Please move on to chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to menu](#menu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
